import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Flatten
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam
import warnings
warnings.filterwarnings('ignore')
sns.set_style("whitegrid")
plt.rcParams['font.sans-serif'] = ['SimHei']  # ä¸­æ–‡æ˜¾ç¤º
plt.rcParams['axes.unicode_minus'] = False

# ======================
# 2. ç”Ÿæˆç¬¦åˆå±…æ°‘ç”¨ç”µç‰¹æ€§çš„æ¨¡æ‹Ÿæ•°æ®é›†
# ======================
def generate_electricity_load(start_date='2023-01-01', days=365):
    """
    ç”Ÿæˆå…·æœ‰çœŸå®æ„Ÿçš„å±…æ°‘ç”¨ç”µè´Ÿè·æ•°æ®ï¼ˆå•ä½ï¼škWï¼‰
    ç‰¹æ€§ï¼šæ—¥å‘¨æœŸæ€§ã€å‘¨å‘¨æœŸæ€§ã€å‘¨æœ«æ•ˆåº”ã€è¶‹åŠ¿ã€å™ªå£°
    """
    np.random.seed(42)
    hours = days * 24
    time_index = pd.date_range(start=start_date, periods=hours, freq='H')
    
    # åŸºç¡€è´Ÿè·ï¼ˆå‡å€¼2.0ï¼‰
    base_load = 2.0
    
    # æ—¥å‘¨æœŸæ€§ï¼ˆæŒ¯å¹…0.8ï¼Œå±…æ°‘ç™½å¤©é«˜ã€å¤œé—´ä½ï¼‰
    hour_sin = np.sin(2 * np.pi * (np.arange(hours) % 24) / 24)
    daily_pattern = 0.8 * hour_sin
    
    # å‘¨å‘¨æœŸæ€§ï¼ˆå·¥ä½œæ—¥é«˜ã€å‘¨æœ«ä½ï¼ŒæŒ¯å¹…0.5ï¼‰
    day_of_week = time_index.dayofweek  # 0=å‘¨ä¸€, 6=å‘¨æ—¥
    weekly_pattern = 0.5 * np.sin(2 * np.pi * day_of_week / 7)
    
    # å‘¨æœ«æ•ˆåº”ï¼ˆå‘¨å…­æ—¥é™ä½20%ï¼‰
    weekend_mask = (day_of_week >= 5).astype(int)  # å‘¨å…­æ—¥ä¸º1
    weekend_effect = -0.4 * weekend_mask
    
    # ç¼“æ…¢å¢é•¿è¶‹åŠ¿ï¼ˆæ¨¡æ‹Ÿç”¨æˆ·å¢é•¿ï¼‰
    trend = 0.0005 * np.arange(hours)
    
    # éšæœºå™ªå£°ï¼ˆé«˜æ–¯+å¶å°”å°–å³°ï¼‰
    noise = 0.15 * np.random.randn(hours)
    spike_events = (np.random.rand(hours) < 0.01).astype(int) * np.random.uniform(0.3, 0.8, hours)
    
    # åˆæˆè´Ÿè·ï¼ˆç¡®ä¿>0ï¼‰
    load = base_load + daily_pattern + weekly_pattern + weekend_effect + trend + noise + spike_events
    load = np.maximum(load, 0.3)  # é¿å…è´Ÿå€¼
    
    # åˆ›å»ºDataFrame
    df = pd.DataFrame({
        'datetime': time_index,
        'load': load
    })
    df.set_index('datetime', inplace=True)
    return df

excel_file_path = r'C:\Users\lenovo\Desktop\ç¬¬30æœŸå¤§åˆ›ç«‹é¡¹å¤šæ™ºèƒ½ä½“ååŒä¼˜åŒ–\æ•°æ®æ±‡æ€».xlsx'  # è¯·æ›¿æ¢ä¸ºä½ çš„å®é™…æ–‡ä»¶è·¯å¾„


try:
    # è¯»å–Excelæ•°æ®
    time_data = pd.read_excel(excel_file_path, sheet_name='æ•°æ®æ±‡æ€»', header=None)
    electricity_load = time_data.iloc[1:8761, 1].values.astype(float)  # è¯»å–ç¬¬ä¸€åˆ—æ•°æ®
    
    # åˆ›å»ºDataFrameæ›¿æ¢åŸæœ‰df
    start_date = '2023-01-01'
    time_index = pd.date_range(start=start_date, periods=len(electricity_load), freq='H')
    df = pd.DataFrame({
        'datetime': time_index,
        'load': electricity_load
    })
    df.set_index('datetime', inplace=True)
    
    print("âœ… çœŸå®æ•°æ®åŠ è½½æˆåŠŸï¼")
    print(f"æ•°æ®å½¢çŠ¶: {df.shape} | æ—¶é—´èŒƒå›´: {df.index.min()} è‡³ {df.index.max()}")
    print(f"è´Ÿè·ç»Ÿè®¡: æœ€å°={df['load'].min():.2f}kW, æœ€å¤§={df['load'].max():.2f}kW, å‡å€¼={df['load'].mean():.2f}kW")
    
except Exception as e:
    print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
    print("ä½¿ç”¨åŸå§‹æ¨¡æ‹Ÿæ•°æ®...")
    df = generate_electricity_load(days=365)  # å¤‡ç”¨æ–¹æ¡ˆ
    print(f"æ•°æ®å½¢çŠ¶: {df.shape} | æ—¶é—´èŒƒå›´: {df.index.min()} è‡³ {df.index.max()}")
    print(f"è´Ÿè·ç»Ÿè®¡: æœ€å°={df['load'].min():.2f}kW, æœ€å¤§={df['load'].max():.2f}kW, å‡å€¼={df['load'].mean():.2f}kW")

# ======================
# 3. å¯è§†åŒ–åŸå§‹æ•°æ®ï¼ˆéªŒè¯åˆç†æ€§ï¼‰
# ======================
def plot_sample_data(df):
    fig, axes = plt.subplots(3, 1, figsize=(14, 10))
    
    # å…¨å¹´è¶‹åŠ¿
    axes[0].plot(df.index, df['load'], linewidth=0.8, color='steelblue')
    axes[0].set_title('å…¨å¹´ç”¨ç”µè´Ÿè·è¶‹åŠ¿', fontsize=14)
    axes[0].set_ylabel('è´Ÿè· (kW)')
    
    # ä¸€å‘¨ç¤ºä¾‹ï¼ˆç¬¬10å‘¨ï¼‰
    week_sample = df['2023-03-06':'2023-03-12']  # é€‰ä¸€å‘¨
    axes[1].plot(week_sample.index, week_sample['load'], marker='o', markersize=3)
    axes[1].set_title('å•å‘¨è´Ÿè·æ³¢åŠ¨ï¼ˆå±•ç¤ºæ—¥å‘¨æœŸæ€§ï¼‰', fontsize=14)
    axes[1].set_ylabel('è´Ÿè· (kW)')
    axes[1].grid(True, linestyle='--', alpha=0.7)
    
    # ä¸€æ—¥ç¤ºä¾‹ï¼ˆå·¥ä½œæ—¥ï¼‰
    day_sample = df['2023-03-08 00:00':'2023-03-08 23:00']
    axes[2].plot(day_sample.index, day_sample['load'], 'ro-', linewidth=2)
    axes[2].set_title('å•æ—¥è´Ÿè·æ›²çº¿ï¼ˆå…¸å‹å·¥ä½œæ—¥ï¼‰', fontsize=14)
    axes[2].set_ylabel('è´Ÿè· (kW)')
    axes[2].set_xlabel('æ—¶é—´')
    axes[2].grid(True, linestyle='--', alpha=0.7)
    
    plt.tight_layout()
    plt.savefig('load_patterns.png', dpi=300, bbox_inches='tight')
    plt.show()

plot_sample_data(df)

# ======================
# 4. æ•°æ®é¢„å¤„ç†ï¼šå½’ä¸€åŒ– + æ„é€ ç›‘ç£å­¦ä¹ æ ·æœ¬
# ======================
def create_dataset(data, look_back=168, look_forward=24):
    """
    å°†æ—¶é—´åºåˆ—è½¬æ¢ä¸ºç›‘ç£å­¦ä¹ æ ¼å¼
    X: [æ ·æœ¬æ•°, look_back, ç‰¹å¾æ•°]  -> è¿‡å»168å°æ—¶
    y: [æ ·æœ¬æ•°, look_forward]       -> æœªæ¥24å°æ—¶
    """
    X, y = [], []
    total_len = len(data)
    for i in range(total_len - look_back - look_forward + 1):
        X.append(data[i:(i + look_back)])
        y.append(data[(i + look_back):(i + look_back + look_forward)])
    return np.array(X), np.array(y)

# å½’ä¸€åŒ–ï¼ˆä»…å¯¹è´Ÿè·å€¼ï¼‰
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_load = scaler.fit_transform(df[['load']]).flatten()  # è½¬ä¸º1Dæ•°ç»„

# æ„é€ æ ·æœ¬ï¼šè¾“å…¥168å°æ—¶ï¼Œé¢„æµ‹24å°æ—¶
LOOK_BACK = 168  # 7å¤©å†å²
LOOK_FORWARD = 24  # é¢„æµ‹24å°æ—¶
X, y = create_dataset(scaled_load, LOOK_BACK, LOOK_FORWARD)

print(f"\nâœ… æ ·æœ¬æ„é€ å®Œæˆï¼")
print(f"è¾“å…¥Xå½¢çŠ¶: {X.shape} -> (æ ·æœ¬æ•°, æ—¶é—´æ­¥168, ç‰¹å¾1)")
print(f"è¾“å‡ºyå½¢çŠ¶: {y.shape} -> (æ ·æœ¬æ•°, é¢„æµ‹æ­¥é•¿24)")
print(f"æ€»æ ·æœ¬æ•°: {len(X)} | å¯è¦†ç›– {len(X)/24:.1f} å¤©çš„è®­ç»ƒçª—å£")

# ======================
# 5. ä¸¥æ ¼æŒ‰æ—¶é—´é¡ºåºåˆ’åˆ†æ•°æ®é›†ï¼ˆç¦æ­¢shuffle!ï¼‰
# ======================
# è®¡ç®—åˆ’åˆ†ç‚¹ï¼ˆ70%è®­ç»ƒ, 15%éªŒè¯, 15%æµ‹è¯•ï¼‰
train_size = int(len(X) * 0.7)
val_size = int(len(X) * 0.15)

X_train, y_train = X[:train_size], y[:train_size]
X_val, y_val = X[train_size:train_size+val_size], y[train_size:train_size+val_size]
X_test, y_test = X[train_size+val_size:], y[train_size+val_size:]

print(f"\nâœ… æ•°æ®é›†åˆ’åˆ†å®Œæˆï¼ˆä¸¥æ ¼æ—¶åºï¼‰:")
print(f"è®­ç»ƒé›†: {X_train.shape} | éªŒè¯é›†: {X_val.shape} | æµ‹è¯•é›†: {X_test.shape}")

# ======================
# 6. æ„å»ºMLPæ¨¡å‹ï¼ˆæ›¿æ¢åŸCNN-LSTMï¼‰
# ======================
def build_mlp_model(input_dim, output_steps):
    """
    æ„å»ºä¼˜åŒ–çš„MLPæ¨¡å‹ï¼ˆé’ˆå¯¹æ—¶åºå±•å¹³ç‰¹å¾ï¼‰
    è¾“å…¥: (æ ·æœ¬æ•°, 168) -> 168ç»´ç‰¹å¾å‘é‡ï¼ˆ7å¤©å†å²è´Ÿè·ï¼‰
    è¾“å‡º: (æ ·æœ¬æ•°, 24) -> æœªæ¥24å°æ—¶è´Ÿè·é¢„æµ‹
    """
    model = Sequential([
        # è¾“å…¥å±‚ + ç¬¬ä¸€éšè—å±‚ï¼ˆå¤§å¹…å¢åŠ å®¹é‡ï¼‰
        Dense(1024, activation='relu', input_shape=(input_dim,)),
        Dropout(0.2),  # å‡å°‘dropouté˜²æ­¢ä¿¡æ¯ä¸¢å¤±
        
        # æ‰¹é‡å½’ä¸€åŒ–å±‚ - é‡è¦æ”¹è¿›ï¼
        tf.keras.layers.BatchNormalization(),
        
        # ç¬¬äºŒéšè—å±‚
        Dense(512, activation='relu'),
        Dropout(0.15),
        tf.keras.layers.BatchNormalization(),
        
        # ç¬¬ä¸‰éšè—å±‚
        Dense(256, activation='relu'),
        Dropout(0.1),
        tf.keras.layers.BatchNormalization(),
        
        # ç¬¬å››éšè—å±‚ï¼ˆæ–°å¢ï¼Œå¢å¼ºè¡¨è¾¾èƒ½åŠ›ï¼‰
        Dense(128, activation='relu'),
        Dropout(0.1),
        tf.keras.layers.BatchNormalization(),
        
        # è¾“å‡ºå±‚ï¼ˆçº¿æ€§æ¿€æ´»ï¼Œå›å½’ä»»åŠ¡ï¼‰
        Dense(output_steps, activation='linear')
    ])
    
    # ç¼–è¯‘ï¼šä¿æŒä¸åŸæ¨¡å‹ä¸€è‡´çš„ä¼˜åŒ–å™¨å’ŒæŒ‡æ ‡
    model.compile(
        loss='mse',
        optimizer=Adam(learning_rate=0.005),
        metrics=['mae']
    )
    return model

# åˆ›å»ºæ¨¡å‹ï¼ˆè¾“å…¥ç»´åº¦=168, è¾“å‡º=24ï¼‰
model = build_mlp_model(LOOK_BACK, LOOK_FORWARD)
print("\nâœ… MLPæ¨¡å‹ç»“æ„:")
model.summary()

# ======================
# 7. è®­ç»ƒæ¨¡å‹ï¼ˆå«æ—©åœå’Œå­¦ä¹ ç‡è°ƒæ•´ï¼‰
# ======================
callbacks = [
    EarlyStopping(
        monitor='val_loss', 
        patience=20, 
        restore_best_weights=True,
        verbose=1
    ),
    ReduceLROnPlateau(
        monitor='val_loss', 
        factor=0.7, 
        patience=5, 
        min_lr=1e-7,
        verbose=1
    )
]

history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=150,  # MLPé€šå¸¸éœ€æ›´å¤šè½®æ¬¡æ”¶æ•›ï¼ˆåŸ100â†’150ï¼‰
    batch_size=64,  # ç¨å¤§batchæå‡æ¢¯åº¦ç¨³å®šæ€§ï¼ˆåŸ32â†’64ï¼‰
    callbacks=callbacks,
    verbose=1
)

# ======================
# 8. æ¨¡å‹è¯„ä¼°ä¸ç»“æœå¯è§†åŒ–
# ======================
# é¢„æµ‹ï¼ˆæµ‹è¯•é›†ï¼‰
y_pred_scaled = model.predict(X_test, verbose=0)

# åå½’ä¸€åŒ–åˆ°åŸå§‹å°ºåº¦
y_test_inv = scaler.inverse_transform(y_test)  # [samples, 24]
y_pred_inv = scaler.inverse_transform(y_pred_scaled)

# è®¡ç®—æ•´ä½“æŒ‡æ ‡ï¼ˆå°†æ‰€æœ‰é¢„æµ‹ç‚¹å±•å¹³è®¡ç®—ï¼‰
flat_true = y_test_inv.flatten()
flat_pred = y_pred_inv.flatten()
mae = mean_absolute_error(flat_true, flat_pred)
rmse = np.sqrt(mean_squared_error(flat_true, flat_pred))
r2 = r2_score(flat_true, flat_pred)

print(f"\nâœ… æµ‹è¯•é›†è¯„ä¼°ç»“æœï¼ˆåå½’ä¸€åŒ–åï¼‰:")
print(f"MAE: {mae:.3f} kW | RMSE: {rmse:.3f} kW | RÂ²: {r2:.4f}")

# å¯è§†åŒ–ï¼šæŸå¤±æ›²çº¿
plt.figure(figsize=(12, 4))
plt.plot(history.history['loss'], label='è®­ç»ƒæŸå¤±', linewidth=2)
plt.plot(history.history['val_loss'], label='éªŒè¯æŸå¤±', linewidth=2)
plt.title('æ¨¡å‹è®­ç»ƒæŸå¤±æ›²çº¿', fontsize=14)
plt.xlabel('Epoch')
plt.ylabel('MSE Loss')
plt.legend()
plt.grid(True, linestyle='--', alpha=0.7)
plt.tight_layout()
plt.savefig('training_loss.png', dpi=300, bbox_inches='tight')
plt.show()

# æ‰“å°é¢„æµ‹å€¼çš„24ä¸ªç‚¹
print(f"\nğŸ“Š æµ‹è¯•é›†ç¬¬1ä¸ªæ ·æœ¬çš„24å°æ—¶é¢„æµ‹ç»“æœ:")
print("=" * 50)
for i, (true_val, pred_val) in enumerate(zip(y_test_inv[0], y_pred_inv[0])):
    hour = i + 1
    error = abs(true_val - pred_val)
    print(f"ç¬¬{hour:2d}å°æ—¶ | çœŸå®å€¼: {true_val:6.2f}kW | é¢„æµ‹å€¼: {pred_val:6.2f}kW | è¯¯å·®: {error:5.2f}kW")

# è®¡ç®—å¹¶æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
mae_sample = mean_absolute_error(y_test_inv[0], y_pred_inv[0])
rmse_sample = np.sqrt(mean_squared_error(y_test_inv[0], y_pred_inv[0]))
print("=" * 50)
print(f"ğŸ“Š è¯¥æ ·æœ¬ç»Ÿè®¡æŒ‡æ ‡:")
print(f"å¹³å‡ç»å¯¹è¯¯å·®(MAE): {mae_sample:.3f} kW")
print(f"å‡æ–¹æ ¹è¯¯å·®(RMSE): {rmse_sample:.3f} kW")
print(f"æœ€å¤§è¯¯å·®: {np.max(np.abs(y_test_inv[0] - y_pred_inv[0])):.3f} kW")
print(f"æœ€å°è¯¯å·®: {np.min(np.abs(y_test_inv[0] - y_pred_inv[0])):.3f} kW")

print(f"\nğŸ“‹ å…¶ä»–æ ·æœ¬é¢„æµ‹ç¤ºä¾‹:")
print("-" * 30)
for sample_idx in [1, 2, 3]:  # æ˜¾ç¤ºå‰3ä¸ªæµ‹è¯•æ ·æœ¬
    if sample_idx < len(y_test_inv):
        sample_mae = mean_absolute_error(y_test_inv[sample_idx], y_pred_inv[sample_idx])
        print(f"æµ‹è¯•æ ·æœ¬{sample_idx}: MAE={sample_mae:.3f}kW")

# å¯è§†åŒ–ï¼šé¢„æµ‹æ•ˆæœå¯¹æ¯”ï¼ˆé€‰å–æµ‹è¯•é›†ç¬¬ä¸€ä¸ªæ ·æœ¬ï¼‰
plt.figure(figsize=(14, 6))
hours = np.arange(1, LOOK_FORWARD + 1)
plt.plot(hours, y_test_inv[0], 'bo-', label='çœŸå®å€¼', linewidth=2, markersize=6)
plt.plot(hours, y_pred_inv[0], 'r^--', label='é¢„æµ‹å€¼', linewidth=2, markersize=6)
plt.title(f'æœªæ¥24å°æ—¶è´Ÿè·é¢„æµ‹ç¤ºä¾‹ï¼ˆæµ‹è¯•é›†ç¬¬1ä¸ªæ ·æœ¬ï¼‰\nMAE={mean_absolute_error(y_test_inv[0], y_pred_inv[0]):.3f}kW', fontsize=14)
plt.xlabel('æœªæ¥å°æ—¶æ•°')
plt.ylabel('è´Ÿè· (kW)')
plt.xticks(hours[::2])  # æ¯2å°æ—¶æ ‡ä¸€ä¸ªåˆ»åº¦
plt.legend(fontsize=12)
plt.grid(True, linestyle='--', alpha=0.7)
plt.tight_layout()
plt.savefig('prediction_comparison.png', dpi=300, bbox_inches='tight')
plt.show()
print(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæ¯•ï¼ç»“æœå·²ä¿å­˜ä¸ºï¼štraining_loss.png å’Œ prediction_comparison.png")

# å¯è§†åŒ–ï¼šé¢„æµ‹æ•ˆæœå¯¹æ¯”ï¼ˆå°†å‰5ä¸ªæµ‹è¯•æ ·æœ¬è¿æˆ120ä¸ªç‚¹ï¼‰
plt.figure(figsize=(15, 6))

# å°†å‰5ä¸ªæ ·æœ¬çš„çœŸå®å€¼å’Œé¢„æµ‹å€¼è¿æ¥æˆ120ä¸ªç‚¹
y_test_concat = np.concatenate([y_test_inv[i] for i in range(min(5, len(y_test_inv)))])
y_pred_concat = np.concatenate([y_pred_inv[i] for i in range(min(5, len(y_pred_inv)))])

# åˆ›å»º120ä¸ªå°æ—¶çš„æ—¶é—´è½´
hours_120 = np.arange(1, len(y_test_concat) + 1)

# ç»˜åˆ¶è¿æ¥çš„120ä¸ªç‚¹
plt.plot(hours_120, y_test_concat, 'bo-', label='çœŸå®å€¼(å‰5æ ·æœ¬)', linewidth=1.5, markersize=4)
plt.plot(hours_120, y_pred_concat, 'r^--', label='é¢„æµ‹å€¼(å‰5æ ·æœ¬)', linewidth=1.5, markersize=4)

# æ·»åŠ æ¯24å°æ—¶çš„åˆ†éš”çº¿æ¥æ ‡è¯†ä¸åŒçš„æ ·æœ¬
for i in range(1, 5):
    plt.axvline(x=i*24, color='gray', linestyle=':', alpha=0.7, linewidth=1)
    plt.text(i*24-12, plt.ylim()[1]*0.95, f'æ ·æœ¬{i}', ha='center', va='top', 
             fontsize=10, bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))

# è®¡ç®—æ•´ä½“MAE
overall_mae = mean_absolute_error(y_test_concat, y_pred_concat)

plt.title(f'è¿ç»­120å°æ—¶è´Ÿè·é¢„æµ‹å¯¹æ¯”ï¼ˆå‰5ä¸ªæµ‹è¯•æ ·æœ¬ï¼‰\næ€»ä½“MAE={overall_mae:.3f}kW', fontsize=14)
plt.xlabel('è¿ç»­å°æ—¶æ•° (120å°æ—¶ = 5ä¸ªæ ·æœ¬ Ã— 24å°æ—¶)')
plt.ylabel('è´Ÿè· (kW)')
plt.xticks(range(0, 121, 12))  # æ¯12å°æ—¶æ ‡ä¸€ä¸ªåˆ»åº¦
plt.legend(fontsize=12)
plt.grid(True, linestyle='--', alpha=0.7)
plt.tight_layout()
plt.savefig('prediction_comparison_120hours.png', dpi=300, bbox_inches='tight')
plt.show()